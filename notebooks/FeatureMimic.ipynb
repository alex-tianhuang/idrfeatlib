{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyheHzU53cXEAJLQ3hBpyz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alex-tianhuang/idrfeatlib/blob/main/notebooks/FeatureMimic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup environment by downloading and installing the idrfeatlib repo.\n",
        "#\n",
        "# You only need to run this once.\n",
        "!file idrfeatlib/ >/dev/null && rm -rf idrfeatlib\n",
        "!git clone https://github.com/alex-tianhuang/idrfeatlib --quiet\n",
        "%pip install idrfeatlib/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQ9P3029XDZ2",
        "outputId": "6ba1ecf8-770f-449a-ced1-34a2930d73b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./idrfeatlib\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: idrfeatlib\n",
            "  Building wheel for idrfeatlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for idrfeatlib: filename=idrfeatlib-0.0.0-py3-none-any.whl size=31311 sha256=d818c5f20b8dc9f239f2daa474f5c1edca26975c4ec16c8b9b010e078e577e2b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lilw9kpa/wheels/fd/73/2d/1c5cfad6d18b968112550482fad0b8617d5ba1997a480307db\n",
            "Successfully built idrfeatlib\n",
            "Installing collected packages: idrfeatlib\n",
            "  Attempting uninstall: idrfeatlib\n",
            "    Found existing installation: idrfeatlib 0.0.0\n",
            "    Uninstalling idrfeatlib-0.0.0:\n",
            "      Successfully uninstalled idrfeatlib-0.0.0\n",
            "Successfully installed idrfeatlib-0.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMLGC_EHWhGB"
      },
      "outputs": [],
      "source": [
        "# Define/prepare design scripts.\n",
        "#\n",
        "# Functions `design_all` and `main` have been adapted from\n",
        "# `idrfeatlib/scripts/feature-mimic.py`.\n",
        "\n",
        "def design_all(tasks):\n",
        "    import tqdm\n",
        "    import sys\n",
        "    import csv\n",
        "    from idrfeatlib.featurizer import Featurizer\n",
        "    acceptable_errors=(ArithmeticError, ValueError, KeyError)\n",
        "    for query, target, protid, regionid, designid, seed, designer, colnames, args in tqdm.tqdm(tasks, desc=\"designing sequences\"):\n",
        "        featurizer = Featurizer(designer.featurizer)\n",
        "        try:\n",
        "            designer.metric.origin, _ = featurizer.featurize(target, acceptable_errors=())\n",
        "        except acceptable_errors as e:\n",
        "            print(\"cannot featurize target (protid=%s,regionid=%s): %s\" % (protid, regionid, e), file=sys.stderr)\n",
        "            return\n",
        "        designer.rng.seed(seed)\n",
        "        AMINOACIDS = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
        "        MAX_RETRIES = 15\n",
        "        if query is None:\n",
        "            for _ in range(MAX_RETRIES):\n",
        "                try_query = \"\".join(designer.rng.choice(AMINOACIDS) for _ in range(len(target)))\n",
        "                try:\n",
        "                    featurizer.featurize(try_query, acceptable_errors=())\n",
        "                except acceptable_errors:\n",
        "                    continue\n",
        "                query = try_query\n",
        "                break\n",
        "            else:\n",
        "                print(\"cannot generate query with all features (protid=%s,regionid=%s,length=%d,seed=%d)\" % (protid, regionid, len(target), seed), file=sys.stderr)\n",
        "                return\n",
        "        try:\n",
        "            if args.keep_trajectory:\n",
        "                save = []\n",
        "                for progress in designer.design_loop(query, acceptable_errors=acceptable_errors):\n",
        "                    save.append(progress)\n",
        "            else:\n",
        "                for progress in designer.design_loop(query, acceptable_errors=acceptable_errors):\n",
        "                    progress.pop(\"Iteration\")\n",
        "                save = [progress]\n",
        "        except acceptable_errors:\n",
        "            print(\"query did not have all features (protid=%s,regionid=%s,seed=%d)\" % (protid, regionid, seed), file=sys.stderr)\n",
        "            return\n",
        "        with open(args.output_file, \"a\") as file:\n",
        "            writer = csv.DictWriter(file, colnames)\n",
        "            for row in save:\n",
        "                row[\"ProteinID\"] = protid\n",
        "                row[\"DesignID\"] = designid\n",
        "                if regionid is not None:\n",
        "                    row[\"RegionID\"] = regionid\n",
        "                if args.save_seed:\n",
        "                    row[\"Seed\"] = seed\n",
        "                writer.writerow(row)\n",
        "\n",
        "\n",
        "def main(args):\n",
        "    from idrfeatlib import FeatureVector\n",
        "    from idrfeatlib.utils import read_nested_csv, iter_nested, read_fasta, read_regions_csv\n",
        "    from idrfeatlib.featurizer import compile_featurizer\n",
        "    from idrfeatlib.native import compile_native_featurizer\n",
        "    from idrfeatlib.metric import Metric\n",
        "    from idrfeatlib.designer import FeatureDesigner, GreedyFeatureDesigner\n",
        "    import os\n",
        "    import json\n",
        "    import sys\n",
        "    import random\n",
        "    import csv\n",
        "    for label, feature_vector in FeatureVector.load(args.feature_weights_file):\n",
        "        if label == args.weights_feature_vector:\n",
        "            metric = Metric(feature_vector, feature_vector)\n",
        "            break\n",
        "    else:\n",
        "        raise RuntimeError(\"could not find feature vector `%s` in %s\" % (args.weights_feature_vector, args.feature_weights_file))\n",
        "\n",
        "    if args.feature_file:\n",
        "        with open(args.feature_file, \"r\") as file:\n",
        "            config = json.load(file)\n",
        "        featurizer, errors = compile_featurizer(config)\n",
        "    else:\n",
        "        featurizer, errors = compile_native_featurizer()\n",
        "    for featname, error in errors.items():\n",
        "        print(\"error compiling `%s`: %s\" % (featname, error), file=sys.stderr)\n",
        "    if featurizer.keys() != metric.weights.as_dict.keys():\n",
        "        raise RuntimeError(\"featurizer and metric feature vector `%s` have different features\" % args.weights_feature_vector)\n",
        "    LENGTH_THRESHOLD = 30\n",
        "    SEED_COLNAME = \"Seed\"\n",
        "    MAX_SEED = 2 ** 64\n",
        "    CONVERGENCE_THRESHOLD = 1e-4\n",
        "    GOOD_MOVES_THRESHOLD = 3\n",
        "    DECENT_MOVES_THRESHOLD = 5\n",
        "    QUERY_COLNAME = \"Sequence\"\n",
        "    if args.greedy:\n",
        "        designer = GreedyFeatureDesigner(featurizer, metric, convergence_threshold=CONVERGENCE_THRESHOLD)\n",
        "        designer.rng = random.Random() # type: ignore\n",
        "    else:\n",
        "        designer = FeatureDesigner(featurizer, metric, covergence_threshold=CONVERGENCE_THRESHOLD, good_moves_threshold=GOOD_MOVES_THRESHOLD, decent_moves_threshold=DECENT_MOVES_THRESHOLD, rng=random.Random())\n",
        "\n",
        "    fa = dict(read_fasta(args.input_sequences))\n",
        "    tasks = []\n",
        "    colnames = [\"ProteinID\"]\n",
        "    featnames = featurizer.keys()\n",
        "\n",
        "    if args.input_regions is None:\n",
        "        colnames += [\"DesignID\", \"Sequence\", \"Time\"]\n",
        "        if args.save_seed:\n",
        "            colnames.append(\"Seed\")\n",
        "        if args.keep_trajectory:\n",
        "            colnames.append(\"Iteration\")\n",
        "        colnames += featnames\n",
        "        fa = {protid: seq for protid, seq in fa.items() if len(seq) >= LENGTH_THRESHOLD}\n",
        "        if args.query_file is None:\n",
        "            if args.seeds_file is None:\n",
        "                n_random = args.n_random or 1\n",
        "                rng = random.Random()\n",
        "                seeds = {protid: [rng.randint(0, MAX_SEED) for _ in range(n_random)] for protid in fa.keys()}\n",
        "            else:\n",
        "                seeds = read_nested_csv(args.seeds_file, 1, group_multiple=True)\n",
        "                seeds = {protid: [row[SEED_COLNAME] for row in rows] for protid, rows in seeds.items() if protid in fa}\n",
        "            for protid, prot_seeds in seeds.items():\n",
        "                if (entry := fa.get(protid)) is None:\n",
        "                    continue\n",
        "                target = entry\n",
        "                assert isinstance(target, str)\n",
        "                for counter, seed in enumerate(prot_seeds):\n",
        "                    seed = int(seed)\n",
        "                    design_id = args.design_id.format(counter=counter, seed=seed, proteinid=protid)\n",
        "                    tasks.append(\n",
        "                        (None, target, protid, None, design_id, seed, designer, colnames, args)\n",
        "                    )\n",
        "        else:\n",
        "            qries = read_nested_csv(args.query_file, 2)\n",
        "            for protid, designid, row in iter_nested(qries, 2):\n",
        "                if (entry := fa.get(protid)) is None:\n",
        "                    continue\n",
        "                target = entry\n",
        "                assert isinstance(target, str)\n",
        "                query = row[QUERY_COLNAME]\n",
        "                tasks.append(\n",
        "                    (query, target, protid, None, designid, None, designer, colnames, args)\n",
        "                )\n",
        "    else:\n",
        "        colnames += [\"RegionID\", \"DesignID\", \"Sequence\", \"Time\"]\n",
        "        if args.save_seed:\n",
        "            colnames.append(\"Seed\")\n",
        "        if args.keep_trajectory:\n",
        "            colnames.append(\"Iteration\")\n",
        "        colnames += featnames\n",
        "        regions = read_regions_csv(args.input_regions)\n",
        "        regions = {protid: ret for protid, entry in regions.items() if (ret := {regionid: (start, stop) for regionid, (start, stop) in entry.items() if stop - start >= LENGTH_THRESHOLD})}\n",
        "        if args.query_file is None:\n",
        "            if args.seeds_file is None:\n",
        "                n_random = args.n_random or 1\n",
        "                rng = random.Random()\n",
        "                seeds = {protid: {regionid: [rng.randint(0, MAX_SEED) for _ in range(n_random)] for regionid in entry.keys()} for protid, entry in regions.items() if protid in fa}\n",
        "\n",
        "            else:\n",
        "                seeds = read_nested_csv(args.seeds_file, 2, group_multiple=True)\n",
        "                seeds = {protid: {regionid: [row[SEED_COLNAME] for row in rows] for regionid, rows in entry.items()} for protid, entry in seeds.items() if protid in fa}\n",
        "            for protid, regionid, region_seeds in iter_nested(seeds, 2):\n",
        "                if (entry := fa.get(protid)) is None:\n",
        "                    continue\n",
        "                target_whole = entry\n",
        "                assert isinstance(target_whole, str)\n",
        "                start, stop = regions[protid][regionid]\n",
        "                target = target_whole[start:stop]\n",
        "                if len(target) != stop - start:\n",
        "                    print(\"invalid region `%s` for protein `%s` (start=%d,stop=%d,seqlen=%s)\" % (regionid, protid, start, stop, len(target_whole)))\n",
        "                    continue\n",
        "                for counter, seed in enumerate(region_seeds):\n",
        "                    seed = int(seed)\n",
        "                    design_id = args.design_id.format(counter=counter, seed=seed, proteinid=protid, regionid=regionid, start=start, stop=stop)\n",
        "                    tasks.append(\n",
        "                        (None, target, protid, regionid, design_id, seed, designer, colnames, args)\n",
        "                    )\n",
        "        else:\n",
        "            qries = read_nested_csv(args.query_file, 3)\n",
        "            for protid, regionid, designid, row in iter_nested(qries, 3):\n",
        "                if (entry := fa.get(protid)) is None:\n",
        "                    continue\n",
        "                target_whole = entry\n",
        "                assert isinstance(target_whole, str)\n",
        "                start, stop = regions[protid][regionid]\n",
        "                target = target_whole[start:stop]\n",
        "                if len(target) != stop - start:\n",
        "                    print(\"invalid region `%s` for protein `%s` (start=%d,stop=%d,seqlen=%s)\" % (regionid, protid, start, stop, len(target_whole)))\n",
        "                    continue\n",
        "                query = row[QUERY_COLNAME]\n",
        "                tasks.append(\n",
        "                    (query, target, protid, regionid, designid, None, designer, colnames, args)\n",
        "                )\n",
        "    if not os.path.exists(args.output_file):\n",
        "        with open(args.output_file, \"w\") as file:\n",
        "            csv.DictWriter(file, colnames).writeheader()\n",
        "        design_all(tasks)\n",
        "        return\n",
        "    with open(args.output_file, \"r\") as file:\n",
        "        reader = csv.DictReader(file)\n",
        "        if reader.fieldnames is None:\n",
        "            with open(args.output_file, \"w\") as file:\n",
        "                csv.DictWriter(file, colnames).writeheader()\n",
        "            design_all(tasks)\n",
        "            return\n",
        "        if reader.fieldnames != colnames:\n",
        "            BOLD_RED = \"\\033[1;31m\"\n",
        "            NORMAL = \"\\033[0m\"\n",
        "            print(BOLD_RED + \"cannot overwrite file `%s` with different column names (shown below):\" % args.output_file + NORMAL, file=sys.stderr)\n",
        "            print(\",\".join(colnames), file=sys.stderr)\n",
        "            sys.exit(1)\n",
        "        if args.keep_trajectory:\n",
        "            checkpoint = [\n",
        "                row for row in reader if row.pop(\"Iteration\") == \"END\"\n",
        "            ]\n",
        "        else:\n",
        "            checkpoint = list(reader)\n",
        "    checkpoint_keys = [\"ProteinID\", \"DesignID\"]\n",
        "    keys = [2, 4]\n",
        "    if args.input_regions is not None:\n",
        "        checkpoint_keys.insert(1, \"RegionID\")\n",
        "        keys.insert(1, 3)\n",
        "    checkpoint = {\n",
        "        tuple(row.pop(key) for key in checkpoint_keys): row for row in checkpoint\n",
        "    }\n",
        "    tasks_not_done = []\n",
        "    for task in tasks:\n",
        "        checkpoint_key = tuple(task[key] for key in keys)\n",
        "        if checkpoint_key not in checkpoint:\n",
        "            tasks_not_done.append(task)\n",
        "    design_all(tasks_not_done)\n",
        "\n",
        "\n",
        "def display_csv(output_name):\n",
        "    \"\"\"\n",
        "    Show the table in the notebook.\n",
        "\n",
        "    I assume colab will forever keep pandas as available by default.\n",
        "    \"\"\"\n",
        "    from IPython.display import display\n",
        "    import pandas as pd\n",
        "\n",
        "    df = pd.read_csv(output_name)\n",
        "\n",
        "    print()\n",
        "    print(\"Showing output below\")\n",
        "    print(\"--------------------\")\n",
        "    print()\n",
        "    display(df)\n",
        "    print()\n",
        "\n",
        "def run_colab_wrapper(output_name):\n",
        "    import argparse\n",
        "    import os\n",
        "    from google.colab import files\n",
        "\n",
        "    args = argparse.Namespace()\n",
        "\n",
        "    args.input_sequences = 'input_sequences.fasta'\n",
        "    goto_upload = True\n",
        "    if os.path.exists(args.input_sequences):\n",
        "        choice = input(f\"The file {args.input_sequences} already exists. Would you like to overwrite it? (y/n)\")\n",
        "        if choice.lower() != 'y':\n",
        "            goto_upload = False\n",
        "    if goto_upload:\n",
        "        files.upload_file(args.input_sequences)\n",
        "\n",
        "    choice = input(\"Would you like to upload a file containing region boundaries? (y/n)\")\n",
        "    if choice.lower() == 'y':\n",
        "        args.input_regions = 'input_regions.csv'\n",
        "        files.upload_file(args.input_regions)\n",
        "    else:\n",
        "        args.input_regions = None\n",
        "\n",
        "    args.feature_file = 'feature_config.json'\n",
        "    goto_upload = True\n",
        "    if os.path.exists(args.feature_file):\n",
        "        choice = input(f\"The file {args.feature_file} already exists. Would you like to overwrite it? (y/n)\")\n",
        "        if choice.lower() != 'y':\n",
        "            goto_upload = False\n",
        "            print(f\"Ignoring {args.feature_file}\")\n",
        "    else:\n",
        "        choice = input(\"Would you like to upload a file containing feature configuration? (y/n)\")\n",
        "        if choice.lower() != 'y':\n",
        "            goto_upload = False\n",
        "    if goto_upload:\n",
        "        files.upload_file(args.feature_file)\n",
        "    else:\n",
        "        args.feature_file = None\n",
        "\n",
        "    args.feature_weights_file = 'feature_weights.csv'\n",
        "    goto_upload = True\n",
        "    if os.path.exists(args.feature_weights_file):\n",
        "        choice = input(f\"The file {args.feature_weights_file} already exists. Would you like to overwrite it? (y/n)\")\n",
        "        if choice.lower() != 'y':\n",
        "            goto_upload = False\n",
        "    if goto_upload:\n",
        "        files.upload_file(args.feature_weights_file)\n",
        "\n",
        "    # Seed arguments (simplified for Colab)\n",
        "    print(\"Choose how to generate query sequences:\")\n",
        "    print(\"1. Randomly sample sequences (provide number)\")\n",
        "    print(\"2. Use seeds from a file (provide file)\")\n",
        "    print(\"3. Provide query sequences in a file\")\n",
        "    choice = input(\"Enter choice (1, 2, or 3): \")\n",
        "\n",
        "    args.n_random = None\n",
        "    args.seeds_file = None\n",
        "    args.query_file = None\n",
        "\n",
        "    if choice == '1':\n",
        "        try:\n",
        "            args.n_random = int(\n",
        "                input(\"Enter the number of random sequences per region/protein: \") \\\n",
        "                    .strip()\n",
        "            )\n",
        "        except ValueError:\n",
        "            print(\"Invalid number. Defaulting to 1 random sequence.\")\n",
        "            args.n_random = 1\n",
        "    elif choice == '2':\n",
        "        args.seeds_file = 'seeds.csv'\n",
        "        print(f\"Please upload the seeds file ({args.seeds_file}):\")\n",
        "        files.upload_file(args.seeds_file)\n",
        "    elif choice == '3':\n",
        "        args.query_file = 'query_sequences.csv'\n",
        "        print(f\"Please upload the query sequences file ({args.query_file}):\")\n",
        "        files.upload_file(args.query_file)\n",
        "    else:\n",
        "        print(\"Invalid choice. Defaulting to 1 random sequence per region/protein.\")\n",
        "        args.n_random = 1\n",
        "\n",
        "    choice = input(\"Would you like to adjust other parameters? Press `n` for defaults (y/n)\")\n",
        "    if choice.lower() == 'y':\n",
        "        args.weights_feature_vector = input(f\"Enter the label for the weights feature vector (default: 'weights'): \") or \"weights\"\n",
        "        args.keep_trajectory = input(\"Keep full trajectory? (y/n): \").lower() == 'y'\n",
        "        args.save_seed = input(\"Save seed in output? (y/n): \").lower() == 'y'\n",
        "        args.design_id = input(\"Enter design ID format string (default: '{counter}'): \") or \"{counter}\"\n",
        "        args.greedy = input(\"Use greedy optimization? (y/n): \").lower() == 'y'\n",
        "    else:\n",
        "        args.weights_feature_vector = \"weights\"\n",
        "        args.keep_trajectory = False\n",
        "        args.save_seed = False\n",
        "        args.design_id = \"{counter}\"\n",
        "        args.greedy = False\n",
        "\n",
        "    args.output_file = output_name\n",
        "    if os.path.exists(args.output_file):\n",
        "        overwrite = input(f\"Output file '{args.output_file}' already exists. Overwrite (w) or append (a)? (w/a): \").lower()\n",
        "        if overwrite == 'w':\n",
        "            os.remove(args.output_file)\n",
        "            print(f\"Output file '{args.output_file}' overwritten.\")\n",
        "        else:\n",
        "            print(\"Output file exists and not overwriting. Will append to it.\")\n",
        "\n",
        "\n",
        "    print(\"Starting design task...\")\n",
        "    main(args)\n",
        "    print(\"Design task finished.\")\n",
        "    display_csv(args.output_file)\n",
        "    print(f\"Downloading output file to {args.output_file}\")\n",
        "    files.download(args.output_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell will:\n",
        "#\n",
        "# 1. Ask for lots of input parameters:\n",
        "#    - (required) a FASTA file of sequences\n",
        "#       - (optional) a CSV file of region boundaries, see extra section below\n",
        "#       - (optional) a JSON file for defining custom features, see extra section below\n",
        "#    - (required) a CSV file of feature weights\n",
        "#                 either for the default features or the user-entered features\n",
        "#    - (optional) five other parameters ...\n",
        "# 2. Design sequences and output them iteratively to `output_features.csv`\n",
        "# 3. Ask to download the output file, called `output_features.csv`\n",
        "#\n",
        "# Run this cell after running the above cells as many times as you would like.\n",
        "\n",
        "run_colab_wrapper(\"output_features.csv\")\n",
        "print(\"Done!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "jKacHNsZ0OFL",
        "outputId": "2c9e9666-608b-4eba-ae82-635924e6792c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The file input_sequences.fasta already exists. Would you like to overwrite it? (y/n)n\n",
            "Would you like to upload a file containing region boundaries? (y/n)n\n",
            "Would you like to upload a file containing feature configuration? (y/n)n\n",
            "The file feature_weights.csv already exists. Would you like to overwrite it? (y/n)n\n",
            "Choose how to generate query sequences:\n",
            "1. Randomly sample sequences (provide number)\n",
            "2. Use seeds from a file (provide file)\n",
            "3. Provide query sequences in a file\n",
            "Enter choice (1, 2, or 3): 1\n",
            "Enter the number of random sequences per region/protein: 10\n",
            "Would you like to adjust other parameters? Press `n` for defaults (y/n)n\n",
            "Starting design task...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "could not convert string to float: 'PAK1'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-10-4166017136.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Run this cell after running the above cells as many times as you would like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mrun_colab_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output_features.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-6-1552711346.py\u001b[0m in \u001b[0;36mrun_colab_wrapper\u001b[0;34m(output_name)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting design task...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Design task finished.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0mdisplay_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-6-1552711346.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_vector\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mFeatureVector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_weights_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_feature_vector\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/idrfeatlib/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, labels)\u001b[0m\n\u001b[1;32m    268\u001b[0m                         \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m                         FeatureVector(\n\u001b[0;32m--> 270\u001b[0;31m                             {\n\u001b[0m\u001b[1;32m    271\u001b[0m                                 \u001b[0mfeatname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0mfeatname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/idrfeatlib/__init__.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    269\u001b[0m                         FeatureVector(\n\u001b[1;32m    270\u001b[0m                             {\n\u001b[0;32m--> 271\u001b[0;31m                                 \u001b[0mfeatname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0mfeatname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'PAK1'"
          ]
        }
      ]
    }
  ]
}